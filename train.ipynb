{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff3a0d-0c43-4065-9415-d6984a1b7e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801a34e-c02b-4eb2-abd3-2ca860d3cc3b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b65680-0206-4bae-99d4-f3ce82167678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452dc47-ec58-4ba9-b2e2-a3f6aae3100e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs = \n",
    "    [\n",
    "      { STEP_NAME: \"data_load\", ENTITY_NAME: \"yolox_pth_pretrain_weights\" }, # pretrain weights prepared on data_load step\n",
    "    ],\n",
    "    # tmp results from previous step\n",
    "    tmp_inputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"obj_detect_train_work_dir\" }  # temporary working dir for train\n",
    "    ],\n",
    "    tmp_entities = \n",
    "    [\n",
    "       { ENTITY_NAME: \"yolox_pth_pretrain_weights\" }, # temporary pretrain weights prepared on data_load step\n",
    "       { ENTITY_NAME: \"obj_detect_inference_files\"} # temporarily stored object detector files \n",
    "    ],\n",
    "    outputs = \n",
    "    [\n",
    "        { ENTITY_NAME: \"obj_detect_inference_files\"} # stored object detector files\n",
    "    ]\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69bc88-8c72-4e2d-988d-f82ad62aee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "### Initializing modules \n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import mmcv\n",
    "from mmengine.config import Config as MmengineConfig\n",
    "\n",
    "import mmdet\n",
    "from mmengine.runner import set_random_seed as mm_set_random_seed\n",
    "\n",
    "import json\n",
    "\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import os.path as osp\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf00e07-8992-4adb-ab21-24ef7cd341d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version of libraries and checking the availability of the cuda kernel\n",
    "assert torch.cuda.is_available(), f\"Cuda not available\"\n",
    "if torch.cuda.is_available():\n",
    "    device_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(device_id)\n",
    "    print(f\"{device_name=}\")\n",
    "    print(f\"{torch.cuda.device_count()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f55b7-0d5e-495e-9b01-8753fc0668d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2bac9a-fa90-4f3d-9789-66da9eddcf7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initializing obj_detector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de183f28-6c05-428b-812f-6248c83b1b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_inputs = substep.tmp_inputs()\n",
    "tmp_entities = substep.tmp_entities()\n",
    "data_load_inputs = substep.inputs(step_name = \"data_load\")\n",
    "\n",
    "train_params = step_params[\"train_params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ad82c-8c17-44ca-aeb8-001afacc3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmengine_cfg_path = os.path.join(tmp_inputs.obj_detect_train_work_dir, 'last_cfg.py')\n",
    "mmengine_cfg = MmengineConfig.fromfile(mmengine_cfg_path)\n",
    "\n",
    "# set random seeds\n",
    "mm_set_random_seed(train_params[\"SEED\"], deterministic=False)\n",
    "\n",
    "# add pretrain weights to mmengine config before training\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_load_inputs.yolox_pth_pretrain_weights, tmp_entity_dir=tmp_entities.yolox_pth_pretrain_weights)\n",
    "\n",
    "yolox_pth_pretrain_weights = glob.glob(f\"{tmp_entities.yolox_pth_pretrain_weights}/*.pth\")\n",
    "mmengine_cfg.load_from = yolox_pth_pretrain_weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae00a2f-6230-4e50-8735-7e4b306b5e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Start obj_detector training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd95162-04e9-4c90-a4c4-fdd96675bc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runner = Runner.from_cfg(mmengine_cfg)\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184db844-5828-4715-bf45-e96690211096",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collecting obj_detect_inference_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832beb9f-ef9f-4ec0-a21a-91903f33b496",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Collecting test image from a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515856d5-2db0-46aa-b9df-32afddf69cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_entities = substep.tmp_entities()\n",
    "\n",
    "val_coco_annotations = {}\n",
    "with open(mmengine_cfg.val_dataloader.dataset.ann_file) as ann_file:\n",
    "    val_coco_annotations = json.load(ann_file)\n",
    "\n",
    "assert val_coco_annotations\n",
    "src_test_image_file_name = osp.join(mmengine_cfg.val_dataloader.dataset.data_prefix.img,\n",
    "                                    val_coco_annotations[\"images\"][0][\"file_name\"]\n",
    "                                   )\n",
    "assert osp.exists(src_test_image_file_name)\n",
    "\n",
    "test_image_file_extension = Path(src_test_image_file_name).suffix\n",
    "dst_test_image_file_name = osp.join(tmp_entities.obj_detect_inference_files, f\"test{test_image_file_extension}\")\n",
    "\n",
    "shutil.copy(src_test_image_file_name, dst_test_image_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b22b1a0-a520-4cfb-908f-c6661af31b31",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Collecting train results\n",
    "(weights, config, test image) for subsequent transfer to other components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eb6e1-50cd-4b53-b875-84a2130df072",
   "metadata": {},
   "source": [
    "Since during the training process intermediate weights of the neural network can be created (for example, for epochs 10, 20, 30, etc.)\n",
    "then it doesn't make much sense to copy all the intermediate files to another step in the pipeline.\n",
    "Therefore, we will copy the weights and the necessary configs into a separate directory and we will copy these files to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cd9f9-d0b1-4c7b-bb7b-05710b62ff17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# copy files - last and best model weights and config model to finished dir\n",
    "shutil.copy(mmengine_cfg.filename, \n",
    "            osp.join(tmp_entities.obj_detect_inference_files, osp.basename(mmengine_cfg.filename))\n",
    "           )\n",
    "\n",
    "with io.open(osp.join(mmengine_cfg.work_dir, \"last_checkpoint\")) as fd:\n",
    "    last_checkpoint = fd.read()\n",
    "out_last_checkpoint = osp.join(tmp_entities.obj_detect_inference_files, \"latest_checkpoint.pth\")\n",
    "shutil.copy(last_checkpoint, out_last_checkpoint)\n",
    "\n",
    "best_models = glob.glob(f\"{mmengine_cfg.work_dir}/*best*.pth\")\n",
    "for fpath in best_models:\n",
    "    shutil.copy(fpath, fpath.replace(mmengine_cfg.work_dir, tmp_entities.obj_detect_inference_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cb9dd-6115-4f22-bb77-5f9bc39b1a69",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Preparing the mmengine config for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e415c-c2f8-429e-aa38-d1d9d1e3d457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cleanup information in train config\n",
    "\n",
    "mmengine_cfg = MmengineConfig.fromfile(osp.join(tmp_entities.obj_detect_inference_files, \"last_cfg.py\"))\n",
    "mmengine_cfg.load_from = \"\"\n",
    "mmengine_cfg.train_dataloader.dataset.dataset.ann_file = \"\"\n",
    "mmengine_cfg.train_dataloader.dataset.dataset.data_prefix=dict(img=\"\")\n",
    "mmengine_cfg.val_dataloader.dataset.ann_file = \"\"\n",
    "mmengine_cfg.val_dataloader.dataset.data_prefix=dict(img=\"\")\n",
    "mmengine_cfg.test_dataloader.dataset.ann_file = \"\"\n",
    "mmengine_cfg.test_dataloader.dataset.data_prefix=dict(img=\"\")\n",
    "mmengine_cfg.val_evaluator.ann_file = \"\"\n",
    "mmengine_cfg.test_evaluator.ann_file = \"\"\n",
    "mmengine_cfg.work_dir = \"\"\n",
    "mmengine_cfg.dump(file=osp.join(tmp_entities.obj_detect_inference_files, \"last_cfg.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa64369-efb6-45fe-8c2d-689ffadaa97a",
   "metadata": {},
   "source": [
    "### Save collected obj_detect_inference_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275ca57-1af4-461b-abb0-c6b5d2dcb145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = substep.outputs()\n",
    "archive.pack_files_from_tmp_to_store(tmp_entity_dir=tmp_entities.obj_detect_inference_files, store_path=outputs.obj_detect_inference_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a2604-bad8-40a4-8c39-b4cabb8ff56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
