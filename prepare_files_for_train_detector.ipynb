{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22dd98-718d-409f-b62f-67b79e10c046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96134cc9-1284-4cf3-9907-fdaf7a3c16f5",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152bec6-c484-4911-b55d-b133855f980c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e383d50f-8470-4e98-923f-6e7242250f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"coco_train_dataset\"}, # train coco dataset from data_prep step\n",
    "      { STEP_NAME: \"data_prep\", ENTITY_NAME: \"coco_eval_dataset\"} # eval coco dataset from data_prep step\n",
    "\n",
    "    ],\n",
    "    tmp_outputs =\n",
    "    [\n",
    "        { ENTITY_NAME: \"coco_train_eval_dataset\" }, # temporary coco datasets for train and eval on next substep\n",
    "        { ENTITY_NAME: \"obj_detect_train_work_dir\"} # temporary mmcv working dir for next substep\n",
    "    ]\n",
    ")\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29765f93-ce58-4c12-9861-04d77560781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "import os.path as osp\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "import mmcv\n",
    "from mmengine.config import Config as MmConfig\n",
    "\n",
    "import mmdet\n",
    "from mmengine.runner import set_random_seed as mm_set_random_seed\n",
    "\n",
    "import json\n",
    "import io, re\n",
    "\n",
    "print(f\"{mmcv.__version__=}\")\n",
    "print(f\"{mmdet.__version__=}\")\n",
    "print(f\"{torch.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfc10f-aecf-4ac0-8fa6-548238997a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version of libraries and checking the availability of the cuda kernel\n",
    "assert torch.cuda.is_available(), f\"Cuda not available\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(device_id)\n",
    "    print(f\"{device_name=}\")\n",
    "    print(f\"{torch.cuda.device_count()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e631c-4a4f-43b1-a3fb-754331060675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fa9795-e379-4e35-8535-0af8e89888fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_prep_inputs = substep.inputs(step_name = \"data_prep\")\n",
    "tmp_outputs = substep.tmp_outputs()\n",
    "\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_prep_inputs.coco_train_dataset, tmp_entity_dir=tmp_outputs.coco_train_eval_dataset)\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_prep_inputs.coco_eval_dataset, tmp_entity_dir=tmp_outputs.coco_train_eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d18eb-0dce-40d1-915f-cdb114679c06",
   "metadata": {},
   "source": [
    "## Setting up the training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593d7df-9e81-451c-a653-a3eed4d32f99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining basic variables for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ebe19-39a8-4952-834f-765eb979b706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = step_params[\"train_params\"]\n",
    "\n",
    "#mm_set_random_seed(train_params['SEED'], deterministic=False)\n",
    "\n",
    "EPOCH_COUNT = train_params['EPOCH_COUNT']\n",
    "BATCH       = train_params['BATCH']\n",
    "WORKERS     = train_params['WORKERS']\n",
    "\n",
    "#MODEL_NAME   = train_params['MODEL_NAME']\n",
    "OPTIMIZER_LR = train_params['OPTIMIZER_LR']\n",
    "WEIGHT_DECAY = train_params['WEIGHT_DECAY']\n",
    "\n",
    "CHECKPOINT_INTERVAL = 5\n",
    "############################################\n",
    "MAX_SIZE       = train_params['MAX_SIZE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f103b86-4f24-494d-a97d-7dce1ecc03ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up basic model training mmengine config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f620dbf-702b-4718-8f83-f6ccdb03b18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolox_cfg_path = osp.join(osp.dirname(mmdet.__file__), '.mim', 'configs', \"yolox\", \"yolox_s_8xb8-300e_coco.py\") \n",
    "mmengine_cfg = MmConfig.fromfile(yolox_cfg_path)\n",
    "\n",
    "# Read class names of objects from train_coco_annotations.json\n",
    "with open(osp.join(tmp_outputs.coco_train_eval_dataset, \"train_coco_annotations.json\")) as f:\n",
    "    train_coco = json.load(f)\n",
    "train_coco_categories = sorted(train_coco[\"categories\"], key=lambda x: x[\"id\"])  # sorted class names of objects by id\n",
    "mmcv_classes = [cat_info.get(\"name\") for cat_info in train_coco_categories] # get class names of objects\n",
    "mmengine_cfg.metainfo = {'CLASSES': mmcv_classes}\n",
    "\n",
    "mmengine_cfg.evaluation = {'metric': ['bbox'], 'save_best' : 'bbox_mAP'}\n",
    "\n",
    "#### set directory for saving model\n",
    "mmengine_cfg.work_dir = tmp_outputs.obj_detect_train_work_dir\n",
    "\n",
    "mmengine_cfg.img_size = (MAX_SIZE, MAX_SIZE)\n",
    "mmengine_cfg.model.bbox_head.num_classes = len(mmcv_classes)\n",
    "mmengine_cfg.model.test_cfg.nms.iou_threshold=0.5\n",
    "\n",
    "#### Set pretain_weights\n",
    "#mmengine_cfg.load_from = tmp_outputs.yolox_pth_pretrain_weights\n",
    "\n",
    "#### Set frozen backbone\n",
    "mmengine_cfg.model.backbone.frozen_stages = 4\n",
    "\n",
    "workflow = [('train', 1), ('val', 1)]\n",
    "mmengine_cfg.workflow = workflow\n",
    "\n",
    "mmengine_cfg.img_norm_cfg = train_params[\"MMCV_NORMALIZE\"]\n",
    "mmengine_cfg.data_root = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2352b5e0-3056-434e-8a19-2de2a3a69861",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuring mmengine pipelines for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd912e5b-2dba-48a1-9c6f-ca178d0b02ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mmengine_cfg.metainfo = {'CLASSES': mmcv_classes}\n",
    "dataset_type = 'CocoDataset'\n",
    "\n",
    "mmengine_cfg.train_pipeline = [\n",
    "    {'type': 'LoadImageFromFile'},\n",
    "    {'type': 'LoadAnnotations', 'with_bbox': True},\n",
    "    {'type': 'MixUp', 'img_scale': (640, 640), 'ratio_range': (0.8, 1.6),'pad_val': 114.0},\n",
    "    {'type': 'Resize', 'scale' : (MAX_SIZE, MAX_SIZE), 'keep_ratio': False},\n",
    "    {'type': 'FilterAnnotations', 'min_gt_bbox_wh': (4.0, 4.0)},\n",
    "    {'type': 'RandomFlip', 'prob': 0.5},\n",
    "    {'type': 'Pad',  'pad_to_square': True,  'pad_val': {'img': (114.0, 114.0, 114.0)}},\n",
    "    {'type': 'Normalize', **mmengine_cfg.img_norm_cfg},\n",
    "     {'type': 'PackDetInputs'}\n",
    "]\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=BATCH,\n",
    "    num_workers=WORKERS,\n",
    "    sampler=dict(type='DefaultSampler', \n",
    "                 shuffle=True),\n",
    "    dataset=dict(type='MultiImageMixDataset',\n",
    "                dataset=dict(type=dataset_type,\n",
    "                            data_root=mmengine_cfg.data_root,\n",
    "                            ann_file=osp.join(tmp_outputs.coco_train_eval_dataset, \"train_coco_annotations.json\"),\n",
    "                            data_prefix=dict(img=tmp_outputs.coco_train_eval_dataset),\n",
    "                            filter_cfg=dict(filter_empty_gt=False, min_size=32), # for empty transporter (wht obj)\n",
    "                            pipeline=[{'type': 'LoadImageFromFile', 'backend_args': None},\n",
    "                                      {'type': 'LoadAnnotations', 'with_bbox': True}],                           \n",
    "                            metainfo=mmengine_cfg.metainfo),\n",
    "                 pipeline=mmengine_cfg.train_pipeline\n",
    "                ),\n",
    "    )\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=BATCH,\n",
    "    num_workers=WORKERS,\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=mmengine_cfg.data_root,\n",
    "        ann_file=osp.join(tmp_outputs.coco_train_eval_dataset, \"val_coco_annotations.json\"),\n",
    "        data_prefix=dict(img=tmp_outputs.coco_train_eval_dataset),\n",
    "        filter_cfg=dict(filter_empty_gt=False, min_size=32), # for empty transporter (wht obj)\n",
    "        pipeline=mmengine_cfg.test_pipeline,\n",
    "        metainfo=mmengine_cfg.metainfo)\n",
    "    )\n",
    "\n",
    "\n",
    "# Modify metric config\n",
    "mmengine_cfg.val_evaluator.ann_file = val_dataloader[\"dataset\"][\"ann_file\"]\n",
    "\n",
    "mmengine_cfg.train_dataloader = train_dataloader\n",
    "mmengine_cfg.val_dataloader = val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed956be-0fea-48aa-9566-11a28b842250",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up the optimizer configuration for model mmengine_cfg.train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c1665-5b29-4778-ae0e-20bc29a98e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the optimizer configuration\n",
    "mmengine_cfg.optimizer = dict(type='Adam', lr=OPTIMIZER_LR)\n",
    "\n",
    "# Configuration for the optimizer wrapper\n",
    "optim_wrapper = dict(  \n",
    "    type='OptimWrapper',  \n",
    "    optimizer=dict(  \n",
    "        type='Adam',  \n",
    "        lr=OPTIMIZER_LR,  # Base learning rate\n",
    "        weight_decay=WEIGHT_DECAY),  # Weight decay\n",
    "    )\n",
    "mmengine_cfg.optim_wrapper = optim_wrapper\n",
    "\n",
    "# Configuration for Training and Testing\n",
    "mmengine_cfg.max_epochs = EPOCH_COUNT\n",
    "mmengine_cfg.train_cfg[\"max_epochs\"] = EPOCH_COUNT\n",
    "mmengine_cfg.train_cfg[\"val_interval\"] = CHECKPOINT_INTERVAL\n",
    "\n",
    "# Configuration for Saving Checkpoints\n",
    "mmengine_cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
    "mmengine_cfg.default_hooks.checkpoint.save_best='auto'\n",
    "mmengine_cfg.resume  = False # resume from the latest checkpoint automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f2348-8e68-4bc5-8fa7-26efd4be87f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Saving prepared config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d722a-e426-4056-88e6-f5174752658e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dump parameters for train substep\n",
    "mmengine_cfg_file = osp.join(tmp_outputs.obj_detect_train_work_dir, \"last_cfg.py\")\n",
    "mmengine_cfg.dump(file=mmengine_cfg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73224531-7fcf-4c6f-bb71-96ed17051afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
